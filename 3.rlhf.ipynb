{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11abe3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/cuda117/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([   1,    1,    0, 9178,   32,   47]),\n",
       " tensor([0, 0, 1, 1, 1, 1]),\n",
       " '<pad><pad><s>how are you')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "prompt_lens = 128\n",
    "gen_lens = prompt_lens + 128\n",
    "\n",
    "from util import TokenizerUtil\n",
    "\n",
    "tokenizer = TokenizerUtil()\n",
    "\n",
    "input_ids, _ = tokenizer.encode('how are you', max_length=6)\n",
    "\n",
    "input_ids, attention_mask = tokenizer.pad_to_left(input_ids)\n",
    "\n",
    "input_ids, attention_mask, tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "835db30b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7144,\n",
       " {'input_ids': tensor([[    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     0, 33837,    35,  5377,\n",
       "            5214, 28122,  8625, 41910,  2103,  1215, 13650,  1215,  5067,    36,\n",
       "           31673,   468, 42499,  2747,     6,   869,   468, 42499,  2747,    43,\n",
       "             864,  5214,   653,    16, 14702,     6,    77,  8251,    16,    22,\n",
       "             495,  1722,  6513,  3121, 22964, 24681,  6267,    35],\n",
       "          [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     0,\n",
       "           33837,    35,  5377,  5214, 28122,  8625, 41910,  2103,  1215, 13650,\n",
       "            1215,  4718,    36, 31673,   468, 42499,  2747,     6,   247,   468,\n",
       "           42499,  2747,     6,    76,   468, 42499,  2747,    43,   864,  5214,\n",
       "            6834, 14702,    34,    10,  5093,     9, 20407,  1245,     6,     8,\n",
       "              10,  2041,  2514,    87, 16344,   116,  6267,    35],\n",
       "          [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     0, 33837,\n",
       "              35,  5377,  5214, 28122,  8625, 41910,  2103,  1215, 13650,  1215,\n",
       "            5334,    36, 21996,  1215,  4684,  5000,   468, 42499,  2747,     6,\n",
       "            1289,   468, 42499,  2747,    43,   864,  5214, 10704,     5,   332,\n",
       "           20257,    13,  1289,     9,   504,   428,  6267,    35],\n",
       "          [    1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "               1,     1,     0, 33837,    35,  5377,  5214, 28122,  8625, 41910,\n",
       "            2103,  1215,  1922,  2517,  4390,  5606,  1215,  1225,    36,  8687,\n",
       "             468, 42499,  2747,     6,   239,  1215, 16552, 12363,   468, 42499,\n",
       "            2747,    43,   864,  5214,  1336,   171,   893,    33,  1855,   260,\n",
       "            3509, 25950,   242,     6,  1236, 12231,  4066,  5954,   261,    36,\n",
       "             398,    43,    25,   239,  3498,   116,  6267,    35]]),\n",
       "  'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1]])})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import default_data_collator\n",
    "\n",
    "dataset = load_dataset(\n",
    "    'json',\n",
    "    data_files='/root/code/DeepSpeed-Chat_my/data/train.json',\n",
    "    split='train')\n",
    "\n",
    "#2,4,4切分,取最后一部分\n",
    "dataset = dataset.select(range(45000, len(dataset)))\n",
    "\n",
    "\n",
    "def f(data):\n",
    "    input_ids, _ = tokenizer.encode(data['prompt'], max_length=prompt_lens)\n",
    "    input_ids, attention_mask = tokenizer.pad_to_left(input_ids)\n",
    "\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "\n",
    "\n",
    "dataset = dataset.map(f, remove_columns=dataset.column_names)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset,\n",
    "                                     collate_fn=default_data_collator,\n",
    "                                     batch_size=4,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)\n",
    "\n",
    "len(loader), next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781c336d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/cuda117/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:107: UserWarning: \n",
      "\n",
      "================================================================================\n",
      "WARNING: Manual override via BNB_CUDA_VERSION env variable detected!\n",
      "BNB_CUDA_VERSION=XXX can be used to load a bitsandbytes version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "If you use the manual override make sure the right libcudart.so is in your LD_LIBRARY_PATH\n",
      "For example by adding the following to your .bashrc: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<path_to_cuda_dir/lib64\n",
      "Loading CUDA version: BNB_CUDA_VERSION=117\n",
      "================================================================================\n",
      "\n",
      "\n",
      "  warn((f'\\n\\n{\"=\"*80}\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 56,623,104 || all params: 387,819,520 || trainable%: 14.600374937290418\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "model_actor = AutoModelForCausalLM.from_pretrained('model/actor')\n",
    "model_actor = get_peft_model(\n",
    "    model_actor,\n",
    "    LoraConfig(inference_mode=False,\n",
    "               r=128,\n",
    "               lora_alpha=128,\n",
    "               target_modules=[\n",
    "                   'q_proj', 'k_proj', 'v_proj', 'fc1', 'fc2', 'out_proj'\n",
    "               ]))\n",
    "model_actor.train()\n",
    "\n",
    "optimizer_actor = torch.optim.Adam(model_actor.parameters(), lr=1e-5)\n",
    "\n",
    "model_actor.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd68dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriticModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rwtransformer = None\n",
    "        self.v_head = None\n",
    "\n",
    "    def get_value(self, input_ids, attention_mask):\n",
    "        value = self.rwtransformer(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask).last_hidden_state\n",
    "        return self.v_head(value).squeeze(2)\n",
    "\n",
    "    def get_reward(self, input_ids, attention_mask):\n",
    "        value = self.get_value(input_ids, attention_mask)\n",
    "\n",
    "        reward = []\n",
    "        for i, v in zip(input_ids, value):\n",
    "            end = input_ids.shape[1] - 1\n",
    "            if tokenizer.eos_token_id in i:\n",
    "                end = i.tolist().index(tokenizer.eos_token_id)\n",
    "            reward.append(v[end])\n",
    "        reward = torch.stack(reward)\n",
    "\n",
    "        return reward\n",
    "\n",
    "\n",
    "model_critic = torch.load('model/critic')\n",
    "model_critic.train()\n",
    "\n",
    "optimizer_critic = torch.optim.Adam(model_critic.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17b9d356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "model_ref = AutoModelForCausalLM.from_pretrained('model/actor')\n",
    "model_reward = torch.load('model/critic')\n",
    "\n",
    "model_ref.eval()\n",
    "model_reward.eval()\n",
    "\n",
    "accelerator = Accelerator(gradient_accumulation_steps=1,\n",
    "                          mixed_precision='fp16')\n",
    "\n",
    "(loader, model_actor, optimizer_actor, model_critic, optimizer_critic,\n",
    " model_ref, model_reward) = accelerator.prepare(loader, model_actor,\n",
    "                                                optimizer_actor, model_critic,\n",
    "                                                optimizer_critic, model_ref,\n",
    "                                                model_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "787e283d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 159])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def get_generate(input_ids, attention_mask):\n",
    "    generate = model_actor.generate(input_ids,\n",
    "                                    attention_mask=attention_mask,\n",
    "                                    max_length=gen_lens,\n",
    "                                    pad_token_id=tokenizer.pad_token_id,\n",
    "                                    eos_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "    lens = (generate[:, prompt_lens:] != tokenizer.pad_token_id).sum(1)\n",
    "\n",
    "    return generate[lens > 1]\n",
    "\n",
    "\n",
    "data = next(iter(loader))\n",
    "\n",
    "get_generate(**data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8687059d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 123])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_prob(prob, index):\n",
    "    prob = prob.log_softmax(dim=2)\n",
    "    prob = prob.gather(dim=2, index=index.unsqueeze(2))\n",
    "    return prob.squeeze(2)\n",
    "\n",
    "\n",
    "get_prob(torch.randn(4, 123, 999), torch.randint(0, 999, (4, 123))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d7d1d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 159]),\n",
       " torch.Size([4, 159]),\n",
       " torch.Size([4, 158]),\n",
       " torch.Size([4, 158]),\n",
       " torch.Size([4, 158]),\n",
       " torch.Size([4]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_generate = None\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_batch(input_ids, attention_mask):\n",
    "    #input_ids -> [b, prompt_lens]\n",
    "    #attention_mask -> [b, prompt_lens]\n",
    "    global last_generate\n",
    "\n",
    "    #根据问题生成回答\n",
    "    #[b, gen_lens]\n",
    "    generate = get_generate(input_ids, attention_mask)\n",
    "\n",
    "    #制作缓存,防止所有回答为空的情况\n",
    "    if len(generate):\n",
    "        last_generate = generate\n",
    "    else:\n",
    "        generate = last_generate\n",
    "\n",
    "    #[b, gen_lens]\n",
    "    generate_mask = (generate != tokenizer.pad_token_id).long()\n",
    "\n",
    "    #两个模型分别取回答被预测到的概率\n",
    "    #[b, gen_lens-1]\n",
    "    prob_old = model_actor(input_ids=generate,\n",
    "                           attention_mask=generate_mask).logits\n",
    "    prob_old = get_prob(prob_old[:, :-1], generate[:, 1:])\n",
    "\n",
    "    #取每个词的value\n",
    "    #[b, gen_lens-1]\n",
    "    value_old = model_critic.get_value(generate, generate_mask)[:, :-1]\n",
    "\n",
    "    #[b, gen_lens-1]\n",
    "    prob_ref = model_ref(input_ids=generate,\n",
    "                         attention_mask=generate_mask).logits\n",
    "    prob_ref = get_prob(prob_ref[:, :-1], generate[:, 1:])\n",
    "\n",
    "    #取回答的分数\n",
    "    #[b]\n",
    "    reward = model_reward.get_reward(generate, generate_mask)\n",
    "\n",
    "    return generate, generate_mask, prob_old, prob_ref, value_old, reward\n",
    "\n",
    "\n",
    "generate, generate_mask, prob_old, prob_ref, value_old, reward = get_batch(\n",
    "    **data)\n",
    "\n",
    "generate.shape, generate_mask.shape, prob_old.shape, prob_ref.shape, value_old.shape, reward.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb227950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 158])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_reward_kl(end, prob_old, prob_ref, reward):\n",
    "    #prob_old -> [b, gen_lens-1]\n",
    "    #prob_ref -> [b, gen_lens-1]\n",
    "    #reward -> [b]\n",
    "\n",
    "    #两份预测概率求kl散度\n",
    "    #[b, gen_lens-1]\n",
    "    reward_kl = -0.1 * (prob_old - prob_ref)\n",
    "\n",
    "    #把原本的reward加在kl散度的最后一个字上\n",
    "    for i, e in enumerate(end):\n",
    "        if e >= reward_kl.shape[1]:\n",
    "            e = -1\n",
    "        reward_kl[i, e] += reward[i].clamp(-5, 5)\n",
    "\n",
    "    #[b, gen_lens-1]\n",
    "    return reward_kl\n",
    "\n",
    "\n",
    "end = generate_mask[:, prompt_lens:].sum(1) + prompt_lens - 1\n",
    "end = end.tolist()\n",
    "\n",
    "reward_kl = get_reward_kl(end, prob_old, prob_ref, reward)\n",
    "\n",
    "reward_kl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf23aae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 31])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#解释见原版代码中的get_delta_note函数\n",
    "def get_delta(value_old, reward_kl):\n",
    "    #value_old -> [b, gen_lens-1]\n",
    "    #reward_kl -> [b, gen_lens-1]\n",
    "\n",
    "    #gen_lens-2 -> prompt_lens-1\n",
    "    delta = []\n",
    "    for i in reversed(range(prompt_lens - 1, value_old.shape[1])):\n",
    "        #[b]\n",
    "        value_next = 0.0\n",
    "        if i != value_old.shape[1] - 1:\n",
    "            value_next = value_old[:, i + 1]\n",
    "\n",
    "        #[b]\n",
    "        d = reward_kl[:, i] + value_next - value_old[:, i]\n",
    "        if len(delta):\n",
    "            d += 0.95 * delta[-1]\n",
    "        delta.append(d)\n",
    "\n",
    "    #[b, gen_lens-prompt_lens]\n",
    "    delta = torch.stack(delta[::-1], dim=1)\n",
    "\n",
    "    return delta\n",
    "\n",
    "\n",
    "delta = get_delta(value_old, reward_kl)\n",
    "\n",
    "delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cf1bcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.2562, device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_loss_actor(prob_new, prob_old, delta, generate_mask):\n",
    "    prob_new = prob_new[:, prompt_lens - 1:]\n",
    "    prob_old = prob_old[:, prompt_lens - 1:]\n",
    "    generate_mask = generate_mask[:, prompt_lens:]\n",
    "\n",
    "    #prob_new -> [b, gen_lens-prompt_lens]\n",
    "    #prob_old -> [b, gen_lens-prompt_lens]\n",
    "    #delta -> [b, gen_lens-prompt_lens]\n",
    "    #generate_mask -> [b, gen_lens-prompt_lens]\n",
    "\n",
    "    #对数概率,求差就是求商,所以这里求的是新旧概率的变化率\n",
    "    #[b, gen_lens-prompt_lens]\n",
    "    ratio = ((prob_new - prob_old) * generate_mask).exp()\n",
    "\n",
    "    #delta是估计出来的去基线Q值,以变化率来缩放Q值\n",
    "    #最大化Q值,以此来寻找最优的actor\n",
    "    #裁剪,防止自举\n",
    "    #[b, gen_lens-prompt_lens]\n",
    "    loss1 = delta * ratio\n",
    "    loss2 = delta * ratio.clamp(0.8, 1.2)\n",
    "    loss = torch.min(loss1, loss2) * generate_mask\n",
    "    loss = loss.sum() / generate_mask.sum()\n",
    "    return -loss\n",
    "\n",
    "\n",
    "loss_actor = get_loss_actor(prob_old, prob_old, delta, generate_mask)\n",
    "\n",
    "loss_actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9a4db24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.4849, device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_loss_critic(value_new, value_old, delta, generate_mask):\n",
    "    value_new = value_new[:, prompt_lens - 1:]\n",
    "    value_old = value_old[:, prompt_lens - 1:]\n",
    "    generate_mask = generate_mask[:, prompt_lens:]\n",
    "\n",
    "    #value_new -> [b, gen_lens-prompt_lens]\n",
    "    #value_old -> [b, gen_lens-prompt_lens]\n",
    "    #delta -> [b, gen_lens-prompt_lens]\n",
    "    #generate_mask -> [b, gen_lens-prompt_lens]\n",
    "\n",
    "    #delta是估计出来的去基线Q值,加上value_old后还原为Q值\n",
    "    #value_new和Q值求mse loss即可,因为value都是对Q函数的估计\n",
    "    #裁剪,防止自举\n",
    "    #[b, gen_lens-prompt_lens]\n",
    "    loss1 = (value_new - delta - value_old)**2\n",
    "    value_new = value_new.clamp(value_old - 0.2, value_old + 0.2)\n",
    "    loss2 = (value_new - delta - value_old)**2\n",
    "\n",
    "    #求平均\n",
    "    loss = torch.max(loss1, loss2) * generate_mask\n",
    "    loss = loss.sum() / 2 / generate_mask.sum()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "loss_critic = get_loss_critic(value_old, value_old, delta, generate_mask)\n",
    "\n",
    "loss_critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "825b4816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.7823232412338257, 13.036150932312012)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(generate, generate_mask, prob_old, prob_ref, value_old, reward):\n",
    "    #generate -> [b, gen_lens]\n",
    "    #generate_mask -> [b, gen_lens]\n",
    "    #prob_old -> [b, gen_lens-1]\n",
    "    #prob_ref -> [b, gen_lens-1]\n",
    "    #value_old -> [b, gen_lens-1]\n",
    "    #reward -> [b]\n",
    "\n",
    "    #求出每句话结束的索引\n",
    "    #[b]\n",
    "    end = generate_mask[:, prompt_lens:].sum(1) + prompt_lens - 1\n",
    "    end = end.tolist()\n",
    "\n",
    "    #结束以后的value归零\n",
    "    for i, e in enumerate(end):\n",
    "        value_old[i, e + 1:] = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        #计算新旧概率的kl散度,再把reward加在最后一个字上\n",
    "        #[b, gen_lens-1]\n",
    "        reward_kl = get_reward_kl(end, prob_old, prob_ref, reward)\n",
    "\n",
    "        #估计去基线的Q值\n",
    "        #[b, gen_lens-prompt_lens]\n",
    "        delta = get_delta(value_old, reward_kl)\n",
    "\n",
    "    #重新计算回答被生成的概率\n",
    "    #[b, gen_lens-1]\n",
    "    prob_new = model_actor(input_ids=generate,\n",
    "                           attention_mask=generate_mask).logits\n",
    "    prob_new = get_prob(prob_new[:, :-1], generate[:, 1:])\n",
    "\n",
    "    #重新计算每个词的value\n",
    "    #[b, gen_lens-1]\n",
    "    value_new = model_critic.get_value(input_ids=generate,\n",
    "                                       attention_mask=generate_mask)[:, :-1]\n",
    "\n",
    "    with accelerator.accumulate(model_actor, model_critic):\n",
    "        #更新actor\n",
    "        loss_actor = get_loss_actor(prob_new, prob_old, delta, generate_mask)\n",
    "        accelerator.backward(loss_actor)\n",
    "        if accelerator.sync_gradients:\n",
    "            accelerator.clip_grad_norm_(model_actor.parameters(), 1.0)\n",
    "        optimizer_actor.step()\n",
    "        optimizer_actor.zero_grad()\n",
    "\n",
    "        #更新critic\n",
    "        loss_critic = get_loss_critic(value_new, value_old, delta,\n",
    "                                      generate_mask)\n",
    "        accelerator.backward(loss_critic)\n",
    "        if accelerator.sync_gradients:\n",
    "            accelerator.clip_grad_norm_(model_critic.parameters(), 1.0)\n",
    "        optimizer_critic.step()\n",
    "        optimizer_critic.zero_grad()\n",
    "\n",
    "        return loss_actor.item(), loss_critic.item()\n",
    "\n",
    "\n",
    "train(generate, generate_mask, prob_old, prob_ref, value_old, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bd3e547",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 7144 0.0432884581387043 0.0044492753222584724 11.086127281188965\n",
      "select max(GOLD) from TABLE_NAME_70 where BRONZE = \"LOST\" and RANK > 5</s>\n",
      "99 7144 -0.04969629645347595 0.0019867706578224897 11.038503646850586\n",
      "select min(BRONZE) from TABLE_NAME_5 where RANK = \"12\" and GOLD < 2</s>\n",
      "149 7144 0.0030154113192111254 0.00020761281484737992 11.152334213256836\n",
      "select count(WEEK_13_nov_26) from TABLE_NAME_18 where WEEK_14_DEC_3 = \"MARY (10-1)\"</s>\n",
      "199 7144 0.009740713983774185 0.0006860442808829248 11.087888717651367\n",
      "select PLAYER from TABLE_10812938_5 where FL_TEAM = \"mART ALOUETES\"</s>\n",
      "249 7144 -0.03482872620224953 0.0013878606259822845 10.923341751098633\n",
      "select VISITOR from TABLE_NAME_20 where HOME = \"LOS Angeles\"</s>\n",
      "299 7144 -0.0376472994685173 0.0012580612674355507 11.025354385375977\n",
      "select FIRST_NAME from REVIEW_Notes where TEACHER_ID = \"3\"</s>\n",
      "349 7144 0.07178817689418793 0.003134319558739662 11.01570987701416\n",
      "select avg(GRID) from TABLE_NAME_29 where DRIVER = \"CLAY REGAZONI\"</s>\n",
      "399 7144 0.039408743381500244 0.0014947608578950167 11.12324333190918\n",
      "select count(PERCENTAGE_40_59_YARDS) from TABLE_29615165_5 where QUANTI = \"dANZERI\"</s>\n",
      "449 7144 0.031342823058366776 0.0007000010227784514 11.008581161499023\n",
      "select TEAM from TABLE_17058178_8 where DATE = \"jANUARY 2\"</s>\n",
      "499 7144 -0.005872503388673067 8.282704948214814e-05 11.010139465332031\n",
      "select SCORE from TABLE_NAME_38 where HOME_TEAM = \" PARK GATE\"</s>\n",
      "549 7144 -0.013427454978227615 0.0007876361487433314 11.073014259338379\n",
      "select ENGINE from TABLE_NAME_98 where DRIVER = \"JANICE\" and CHASSIS = \" 003 002 005 006 005 006 006 005 006 005 006 005 005 006\"</s>\n",
      "599 7144 0.03763757273554802 0.0008918892126530409 11.024370193481445\n",
      "select count(YEAR) from TABLE_NAME_27 where FINISH = \"3\"</s>\n",
      "649 7144 -0.0005419233348220587 0.00017722498159855604 11.094087600708008\n",
      "select sum(MCCIN_NUMBER) from TABLE_20722805_1 where BRANCESS = \"mILLERS\"</s>\n",
      "699 7144 -0.017016621306538582 0.0003107616794295609 11.0762939453125\n",
      "select ENGINE from TABLE_2503102_1 where CAR_PRIX = \"fuzzy\"</s>\n",
      "749 7144 -0.04725843295454979 0.0017662483733147383 10.972904205322266\n",
      "select STATUS from TABLE_NAME_20 where AREA_KM_2 = \"75.35\" and OFFICIAL_NAME = \"SUsex\"</s>\n",
      "799 7144 -0.012215489521622658 0.00019981252262368798 11.112321853637695\n",
      "select sum(WINS) from TABLE_NAME_84 where CLUB = \"TERANG\" and DRAWSS < 0</s>\n",
      "849 7144 0.026457909494638443 0.0004845383227802813 10.937128067016602\n",
      "select LATITUDE from TABLE_18600760_8 where geo_ID = \"3810536900\"</s>\n",
      "899 7144 0.0037013706751167774 9.555693395668641e-05 11.005757331848145\n",
      "select count(ATTENDANCE) from TABLE_NAME_28 where DATE = \"APril 14\"</s>\n",
      "949 7144 0.03339049592614174 0.0006685544503852725 11.013387680053711\n",
      "select sum(CROWD) from TABLE_NAME_7 where VENUE = \"MCg\"</s>\n",
      "999 7144 0.05007590726017952 0.001736942445859313 10.986948013305664\n",
      "select sum(YEAR) from TABLE_NAME_12 where RESULT = \"5TH RESULT\"</s>\n",
      "1049 7144 -0.01568465866148472 0.00016985741967801005 10.939109802246094\n",
      "select RESidence_hall from TABLE_15873547_1 where M mascot = \"VERMIN\"</s>\n",
      "1099 7144 -0.006910024676471949 0.00016588918515481055 11.000265121459961\n",
      "select DATE from TABLE_NAME_36 where WEEK = \"GRASS\" and ROUND = \"RASS\"</s>\n",
      "1149 7144 -0.017192037776112556 0.0002646187786012888 11.061003684997559\n",
      "select CATEGORY from TABLE_28628309_9 where PLAYER = \"OLLE RACESEN RACESENELA\"</s>\n",
      "1199 7144 -0.007759253028780222 0.0002844390401151031 10.99275016784668\n",
      "select del_PueblO from TABLE_15977768_1 where CENTER = \"1988 1988\"</s>\n",
      "1249 7144 -0.008707055822014809 0.00013972364831715822 11.130319595336914\n",
      "select STUDIO_HOST from TABLE_NAME_47 where PLAY_BY_PLAY = \"SEAN GRANDE\" and YEAR = 2004-05\"</s>\n",
      "1299 7144 -0.013096445240080357 0.00012072958634234965 11.064050674438477\n",
      "select margin_OF_VICTORY from TABLE_NAME_7 where WINNER = \"NIKki GERrett\"</s>\n",
      "1349 7144 0.012550677172839642 0.0002007674047490582 10.938095092773438\n",
      "select NAME from ARTER where YEAR_JOINED = \"UNITED STATES\" and COUNTRY = \"UNITED STATES\"</s>\n",
      "1399 7144 0.013168277218937874 0.00013247372407931834 11.006296157836914\n",
      "select VENUE from TABLE_NAME_2 where COMPETITION = \"2010 FIFA WORLD Cup QUALIFICATION\"</s>\n",
      "1449 7144 0.01373349130153656 0.0002705644292291254 11.087900161743164\n",
      "select AGAINST from TABLE_23314951_4 where OPPONENT = \"kERSKY pILL\"</s>\n",
      "1499 7144 0.020330576226115227 0.0002665547071956098 11.010038375854492\n",
      "select HOME_TEAM from TABLE_NAME_33 where TIE_NO = \"HOME\"</s>\n",
      "1549 7144 -0.05354849994182587 0.001698397914879024 11.015522956848145\n",
      "select RECORD from TABLE_NAME_72 where DATE = \"OCTOBER 27\"</s>\n",
      "1599 7144 -0.008640706539154053 0.00020617818518076092 11.121171951293945\n",
      "select count(YEAR) from TABLE_NAME_21 where REG_SEASON = \"3RD ROUND\" and OPEN_CUP = \"3RD ROUND\"</s>\n",
      "1649 7144 -0.01351992692798376 0.0002720367338042706 11.130392074584961\n",
      "select TO_WINNER_TEAM from TABLE_13657749_2 where GAU_WINNING_TEAM = \"27 dONLIZAR\"</s>\n",
      "1699 7144 0.01832485944032669 0.0009287465363740921 11.095481872558594\n",
      "select max(SEASON) from TEAM as T1 join TEAM as T1 join TEAM as T1 join TEAM as TEMPERATURE as T1 join TEAM as TEMPERATURE as T1 on T1.SLAWARD = TEMPERATURE where T1 join TEAM_ID = TEMPERATURE</s>\n",
      "1749 7144 -0.014402474276721478 0.0002805536787491292 11.011598587036133\n",
      "select RESULT from TABLE_NAME_90 where GAME_SITE = \"SPURFER\"</s>\n",
      "1799 7144 0.03556646406650543 0.0008249643724411726 10.83353328704834\n",
      "select CITY from TABLE_NAME_70 where PROVINATION = \"SASASASSA\"</s>\n",
      "1849 7144 -0.002349701477214694 0.00010787652718136087 10.975189208984375\n",
      "select DATE from TABLE_NAME_70 where SPORT = \"ACEMICALS\"</s>\n",
      "1899 7144 -0.03865614905953407 0.0014181226724758744 11.091004371643066\n",
      "select IAMMITY from TABLE_28742659_2 where FINISH = \"3RD voted OUT DAY 9\"</s>\n",
      "1949 7144 -0.007477611768990755 0.000110842905996833 11.01302719116211\n",
      "select DIRECTED_BY from TABLE_2221484_2 where SERIES__NUMBER = 266</s>\n",
      "1999 7144 7.601110701216385e-05 0.000175545021193102 11.115843772888184\n",
      "select max(WEEK) from TABLE_NAME_92 where RESULT = \"W 23-20\" and ATTENDANCE < 34 offset 077</s>\n",
      "2049 7144 -0.0370536707341671 0.0008719725301489234 11.031017303466797\n",
      "select TIE_NO from TABLE_NAME_98 where HOME_TEAM = \"SCORERS\"</s>\n",
      "2099 7144 -0.025249164551496506 0.00040864277980290353 11.035436630249023\n",
      "select LEAD from TABLE_NAME_79 where THIRD = \"ARA GEORGE\"</s>\n",
      "2149 7144 0.0025955173186957836 0.00013905837840866297 11.046173095703125\n",
      "select 1999 from TABLE_NAME_2 where Q1 = \"Q1\" and Q3 = \"Q3\"</s>\n",
      "2199 7144 -0.004012614954262972 0.00010875255975406617 10.960079193115234\n",
      "select sum(PICK__NUMBER) from TABLE_16575609_4 where COLLEGE = \"dEWMONTON eESKOS\"</s>\n",
      "2249 7144 -0.018373383209109306 0.0002556181570980698 11.067780494689941\n",
      "select count(OPOSES) from TABLE_22801331_1 where RECORD = \"1-0\"</s>\n",
      "2299 7144 -0.030244722962379456 0.0005659692105837166 10.947672843933105\n",
      "select IATA from TABLE_NAME_32 where IATA = \"ZGLK\"</s>\n",
      "2349 7144 -0.021098358556628227 0.00036842611734755337 11.024419784545898\n",
      "select sum(WEEK) from TABLE_23624542_4 where ATTENDANCE = \"10402\"</s>\n",
      "2399 7144 -0.023704545572400093 0.0005208735237829387 10.727806091308594\n",
      "select NAME from rOVERS where TITLE = \"rOVERS\"</s>\n",
      "2449 7144 0.017688345164060593 0.0003368206089362502 11.00783920288086\n",
      "select HANzi from TABLE_NAME_69 where LAUNCH = \"PHIL\" and NAME = \"FERN\"</s>\n",
      "2499 7144 -0.015926025807857513 0.0002283884969074279 10.899129867553711\n",
      "select NARRATOR from TABLE_1681535_1 where NOTES = \"fRASER HINE\"</s>\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(loader):\n",
    "    #生成数据\n",
    "    (generate, generate_mask, prob_old, prob_ref, value_old,\n",
    "     reward) = get_batch(**data)\n",
    "\n",
    "    #训练\n",
    "    loss_actor, loss_critic = train(generate, generate_mask, prob_old,\n",
    "                                    prob_ref, value_old, reward)\n",
    "\n",
    "    if (i + 1) % 50 == 0:\n",
    "        print(i, len(loader), loss_actor, loss_critic, reward[0].item())\n",
    "        print(tokenizer.decode(generate[0, prompt_lens:]))\n",
    "\n",
    "    if i == 2500:\n",
    "        break\n",
    "\n",
    "model_actor.merge_and_unload().save_pretrained('model/rlhf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cuda117]",
   "language": "python",
   "name": "conda-env-cuda117-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
